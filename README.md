### Ciao, nice to meet you 👋

I'm Simone, a Computer Engineer currently working as Machine Learning Engineer [@Generali Italia](https://www.generali.it).   
I enjoy facing complex problems, building things from scratch, and learning new stuff.

### 🎓 Education
* Master of Science in Computer Science and Engineering from Politecnico di Milano, with a focus on **Machine Learning**, Data Science, **Software Engineering**. Final Grade 108/110.
* Bachelor of Science in Computer Science from Università di Genova, with a focus on **Software Engineering** and theoretical computer science. Final Grade 105/110.

### 👨🏽‍💻 Working Experience
* **Generali Italia** | Machine Learning Software Engineer, January 2022 - present
Working in the Advanced Analytics team to build AI solutions and products for internal/external customers.
  * Led a ML engineering group of 4 personnel to build a MLOps framework to standardize the process of training and deploying
    models to production, evaluate the current state-of-the-art solution, the various limitations, and oversee all aspects of full-stack development.
  * Coordinated with a cross-functional team of 6+ engineers to design and develop a B2C event-based microservices architecture
    by leveraging computer vision models to estimate car damage.
  * As part of the platform team, consistently identified innovative solutions and enhancements to improve internal frameworks
    utilized by a workforce of over 80 engineers.

* **Mia-Platform** | Software Engineer, May 2020 - December 2021
Mia-Platform is a product based company which provides a console to manage the entire DevOps Stream and master end-to-end enterprise digital platforms based on APIs, microservices and Fast Data.
  * Designed and implemented 30+ microservices architectures, utilizing Docker and Kubernetes, fully integrated in Mia-Platform
    PaaS. Frequently operating through RESTful APIs and event-driven design choices as Kafka streams, enhancing system
    responsiveness.
  * Optimized data ingestion processes into a centralized Data Lake (MongoDB) leveraging 50+ Apache Kafka streams. This
    initiative significantly improved the platform's ability to handle and process large volumes of data in real-time.
  * Achieved a 30% improvement in raw data aggregation time by redesigning and implementing highly performant MongoDB
  aggregation pipelines. These optimizations significantly reduced the quantity of errors and latency.
  * Implemented comprehensive monitoring and logging solutions, such as Prometheus and Grafana, to proactively identify
  performance bottlenecks and troubleshoot issues, resulting in reduction in incident response times

* **Boston University SecLab** | Research Assistant, January-March 2020
  * Collected and processed 1M+ social media posts from Twitter, Reddit, and Facebook ranging in a time span of 2 years.
  * Performed sentiment and temporal analysis on URLs to assess the problem of news dissemination by.
  * Evaluated the dissemination of malicious content between platforms using a Hawkes Process statistical model structure       implemented in Python.

### 🤔 What do I do when I'm not at my laptop?
  - I love surfing 🏄.
  - I often read biographies 📚. Spare -> [Spare: Prince Harry](https://www.amazon.it/Spare-English-Sussex-Prince-Harry-ebook/dp/B0BJV8XM2W).
  - I'm always in for a good cup of espresso ☕.



### 📫 Main Projects
* [`Predicting cars speed`](https://github.com/simo955/Predicting_cars_speed) : Built an ensemble of two gradient-boosted trees models (**Catboost** and **LightGBM**) to predict traffic average speeds at specific times and locations on Italian roads.
* [`Trading deamon/bot`](https://github.com/simo955/traiding_deamon) : Independently developed a Python Telegram bot that continuously fetches the price of a specified stock and alerts the user if there is a sudden increase or decrease in relation to the average of the past n prices. The bot is currently available to the public at @trading\_deamon\_bot .
* [`Recommender Systems Challenge`](https://github.com/simo955/RecSys_2018) : participated in a competition that aggregated the results of six different submissions on Kaggle over a period of six months. The goal was to recommend 10 tracks for each of 10,000 given playlists, and I built a **hybrid recommender** system combining both content-based filtering and collaborative filtering techniques using Python. I achieved a final position of 12th out of 80 teams, and was in the top 5 for five months, reaching the highest possible evaluation.
	


### Thank you for reading!
